{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 기사 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지로딩\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7364cef2654e499e66e41eac5df914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=612.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "크롤링시작\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b955e8322142628e4cd15dc161ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14324.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm #pip install tqdm\n",
    "link_list = [];titles = [];dates = [];weeks = [];times=[]\n",
    "weekDays = (\"월\",\"화\",\"수\",\"목\",\"금\",\"토\",\"일\")\n",
    "\n",
    "\n",
    "#종목코드\n",
    "code = '005380'\n",
    "#크롤링할 페이지\n",
    "startpage = 1\n",
    "lastpage = 612\n",
    "\n",
    "#크롤링\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
    "print('페이지로딩')\n",
    "for page in tqdm(range(startpage,lastpage+1)):\n",
    "    res = requests.get(f'https://finance.naver.com/item/news_news.nhn?code={code}&page={page}', headers = headers)\n",
    "    soup = bs(res.content, 'lxml')\n",
    "    href_list = soup.select('td.title > a')\n",
    "    for i in href_list:\n",
    "        link_list.append(\"https://finance.naver.com\"+i['href'])      \n",
    "print(\"크롤링시작\")\n",
    "for j in tqdm(link_list):\n",
    "    link_res = requests.get(j, headers = headers)\n",
    "    soup = bs(link_res.content, 'lxml')\n",
    "    try:\n",
    "        news_title = soup.select_one('th > strong').text  \n",
    "        date , time = soup.select_one('th > span > span').text.split()\n",
    "        year , month , day = date.split('.')\n",
    "        get_weekday = datetime.date(int(year),int(month),int(day))\n",
    "        hour, minute = time.split(':')   \n",
    "        time = (60 * int(hour) + int(minute))//15  \n",
    "        weeks.append(weekDays[get_weekday.weekday()]) \n",
    "        date = date.replace('.','')\n",
    "        titles.append(news_title)\n",
    "        dates.append(int(date))       \n",
    "        times.append(time)\n",
    "    except:\n",
    "        continue\n",
    "   \n",
    "    \n",
    "    \n",
    "#dataframe  \n",
    "dic = {'날짜':dates,'요일':weeks,'시간':times, '제목':titles}\n",
    "crawling_data = pd.DataFrame(dic)\n",
    "#저장\n",
    "crawling_data.to_csv('D:/Users/A1-102-u12/210222/20년3월 현대차.csv',encoding=\"\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe  \n",
    "dic = {'날짜':dates,'요일':weeks,'시간':times, '제목':titles}\n",
    "crawling_data = pd.DataFrame(dic)\n",
    "#저장\n",
    "crawling_data.to_csv('D:/Users/A1-102-u12/210222/20년3월 HMM.csv',encoding=\"\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#지금까지했던거 합쳐서 데이터셋 만들기\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/넷마블_완료.csv\", encoding=\"euc-kr\")\n",
    "df2 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/GS건설_완료.csv\", encoding=\"euc-kr\")\n",
    "df3 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/더존비즈온_완료.csv\", encoding=\"euc-kr\")\n",
    "df4 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/삼성중공업_완료.csv\", encoding=\"euc-kr\")\n",
    "df5 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/에넥스_완료.csv\", encoding=\"euc-kr\")\n",
    "df6 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/위니아딤채_완료.csv\", encoding=\"euc-kr\")\n",
    "df7 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/한국전력_완료.csv\", encoding=\"euc-kr\")\n",
    "df8 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/코오롱_완료.csv\", encoding=\"euc-kr\")\n",
    "df9 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/한국항공우주_완료.csv\", encoding=\"euc-kr\")\n",
    "df10 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/한화생명_완료.csv\", encoding=\"euc-kr\")\n",
    "df11 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/한화솔루션_완료.csv\", encoding=\"euc-kr\")\n",
    "df12 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/현대건설_완료.csv\", encoding=\"euc-kr\")\n",
    "df13 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/신라젠_완료.csv\", encoding=\"euc-kr\")\n",
    "df14 = pd.read_csv(\"D:/Users/A1-102-u12/210219/2월19일완료/SK하이닉스_완료.csv\", encoding=\"euc-kr\")\n",
    "df15 = pd.read_csv(\"D:/Users/A1-102-u12/210218_dataset.csv\", encoding='euc-kr')\n",
    "dataset = pd.concat([df1, df2, df3, df4, df5, df6, df7,df8, df9,df10,df11,df12,df13,df14,df15])\n",
    "dataset= dataset.reset_index(drop=True)\n",
    "dataset.to_csv('210219_dataset.csv',encoding=\"\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#주식데이터 encoding=\"euc-kr\"\n",
    "data = pd.read_csv(\"C:/Users/young/210222주식/휴마시스.csv\",encoding=\"euc-kr\")\n",
    "#날짜 수정\n",
    "dateList=[]; timeList=[]; \n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        dateList.append(int(data['날짜'][i].replace(\"-\",\"\")))\n",
    "    except:\n",
    "        dateList.append(int(data['날짜'][i].replace(\"/\",\"\")))\n",
    "data['Date'] = dateList\n",
    "\n",
    "for i in range(len(data)):\n",
    "    hour, minute, sec = data['시간'][i].split(':')\n",
    "    timeList.append((60*int(hour)+int(minute))//15)\n",
    "data['Time'] = timeList\n",
    "\n",
    "\n",
    "#15분사이 변하는 값\n",
    "data['Close-Open'] = data['종가']-data['시가']\n",
    "\n",
    "\n",
    "#15분사이 상승 = 1\n",
    "#하락 = -1\n",
    "#변화없음 = 0\n",
    "data['C-O'] = 0\n",
    "data.loc[data['Close-Open'] > 0,'C-O'] = 1\n",
    "data.loc[data['Close-Open'] < 0,'C-O'] = -1\n",
    "\n",
    "data = data[['Date','Time','C-O']]\n",
    "#크롤링한 데이터를 가져옴 data = 주가데이터 / crawling_data = 크롤링데이터\n",
    "crawling_data = pd.read_csv(\"C:/Users/young/210222/휴마시스.csv\",encoding=\"cp949\")\n",
    "\n",
    "list1 = []\n",
    "\n",
    "#토요일\n",
    "crawling_data.loc[crawling_data['요일'] == '토', '날짜'] += 2\n",
    "crawling_data.loc[crawling_data['요일'] == '토', '시간'] = 36\n",
    "#일요일\n",
    "crawling_data.loc[crawling_data['요일'] == '일', '날짜'] += 1\n",
    "crawling_data.loc[crawling_data['요일'] == '일', '시간'] = 36\n",
    "#주중 장외\n",
    "crawling_data.loc[crawling_data['시간'] >= 62, '날짜'] += 1\n",
    "crawling_data.loc[crawling_data['시간'] >= 62, '시간'] = 36\n",
    "crawling_data.loc[crawling_data['시간'] < 36, '시간'] =36\n",
    "\n",
    "#상승/하락 구하기.\n",
    "for i in range(len(crawling_data)):\n",
    "    try:\n",
    "        temp = data[data['Time'] == crawling_data['시간'][i]]    \n",
    "        temp2 = temp[temp['Date'] == crawling_data['날짜'][i]]\n",
    "        list1.append(temp2['C-O'].values[0])        \n",
    "    except:        \n",
    "        list1.append(np.nan)\n",
    "        \n",
    "crawling_data['상승/하락'] = list1\n",
    "\n",
    "\n",
    "#필요한 열만 가져가자\n",
    "crawling_data = crawling_data[['제목','상승/하락']]\n",
    "\n",
    "#중복값제거\n",
    "crawling_data = crawling_data.drop_duplicates(['제목'], keep = 'last') \n",
    "\n",
    "#결측치제거\n",
    "crawling_data.dropna(inplace = True)\n",
    "\n",
    "#0인값을 없애고 -1을 0으로 바꾼다.\n",
    "temp1 = crawling_data[crawling_data['상승/하락'] == 0].index\n",
    "crawling_data = crawling_data.drop(temp1)\n",
    "crawling_data.loc[crawling_data['상승/하락'] == -1, '상승/하락'] = 0\n",
    "crawling_data= crawling_data.reset_index(drop=True)\n",
    "crawling_data.to_csv('C:/Users/young/210222/완료/휴마시스.csv',encoding=\"\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>상승/하락</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'일곱 개의 대죄' 글로벌 앱스토어 매출 톱3 등극</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ 기업가치평가 부담 탈피…기존 게임 감소세 관리해야”</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>고평가 부담 탈피…신작일정별 대응 유효-이베스트</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>신규 게임 출시·실적 적중률↑…“긍정적”-메리츠</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>기존 라인업 매출 하향세..목표가↓-KTB</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>코로나19에 말라리아 치료제 효과 소식에  강세</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8194</th>\n",
       "      <td>(019170) 현재 +9.63%</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8195</th>\n",
       "      <td>'' 5% 이상 상승 단기·중기 이평선 정배열로 상승세</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>'' 5% 이상 상승 전일 외국인 대량 순매도</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>27일 정기 주총 소집</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  제목  상승/하락\n",
       "0       '일곱 개의 대죄' 글로벌 앱스토어 매출 톱3 등극    1.0\n",
       "1     “ 기업가치평가 부담 탈피…기존 게임 감소세 관리해야”    0.0\n",
       "2         고평가 부담 탈피…신작일정별 대응 유효-이베스트    0.0\n",
       "3         신규 게임 출시·실적 적중률↑…“긍정적”-메리츠    0.0\n",
       "4            기존 라인업 매출 하향세..목표가↓-KTB    0.0\n",
       "...                              ...    ...\n",
       "8193      코로나19에 말라리아 치료제 효과 소식에  강세    0.0\n",
       "8194              (019170) 현재 +9.63%    0.0\n",
       "8195  '' 5% 이상 상승 단기·중기 이평선 정배열로 상승세    1.0\n",
       "8196       '' 5% 이상 상승 전일 외국인 대량 순매도    1.0\n",
       "8197                    27일 정기 주총 소집    1.0\n",
       "\n",
       "[8196 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeList2 = ['[주간추천주]', '[현장에서]', '[富를 키우는 투자지표]', '[다시보는 리포트]', '[전문기자칼럼]', '[위클리 마켓]', '[주말n입사지원]',\n",
    " '[빅데이터로 본 재테크]', '[주요 크레딧 공지]', '[ 컨콜]', '[잠정실적]', '이데일리', '[Worst]', '[임상의 맥]', '[기업공시]',\n",
    " '[이태호의 캐피털마켓 워치]', '[코스피 마감]', '[하나금투 주간추천주]', '[itM-특징주]', '[오늘의 목표주가]',\n",
    " '[fnRASSI]', '[이슈타임]', '[주간HOT종목]', '[김대성의 종목분석]', '[뒷북경제]', '[마켓인사이드]', '[한경 팩트체크]', '[뉴스새벽배송]',\n",
    " '[이데일리N]', '[김영수의 현장클릭]', '[SK證 주간추천주]', '[코스닥人]', '[이번주 추천주]', \"['약'한뉴스]\", '[현장클릭]', '[홍길용의 화식열전]',\n",
    "  '[줌인]', '[어떻게 생각하십니까]', '[동정]', '[미리보는 이데일리 신문]', '[중기info]', '[숫자로 본 K바이오]',\n",
    " '[INSIDE]', '[오후시황]', '[인터뷰]', '[fn마켓워치]', '[시그널FOCUS]', '[CB 발행 그후]①', '[fm마켓워치]',\n",
    " '[공시]', '[IT선빵!]', '[클릭 e종목]', '[서경스타즈IR]', '[장외로 번진 투자열기]', '[마켓브리핑]', '[2020자본투자대상]',\n",
    " '[2020국감]', '[특별기고]', '[머니콕]', '[Q&A]', '[프로필]', '[신년사]', '[특징주]', '[Hot-Line]', '[오늘장 미리보기]', '[포스트IPO]⑩',\n",
    "  '[일문일답]', '[종목 돋보기]', '[23일 주요 크레딧 공시]', '[itM]', '[주목!e스몰캡]', '[SK증권 주간추천주]', '[줌인 이종목]',\n",
    " '[시그널]', '[줌인리더스클럽]', '[속보]', '[마감시황]', '[마켓포인트]', '[마켓뷰]', '[MBN GOLD 시황저격]', '[위클리M&A]', '[마켓인]',\n",
    "  '[유가증권 메모]', '[단독]', '[31st SRE]', '[강세 토픽]', '[유안타證 주간추천주]', '[다시 보는 리포트]', '[피플]',\n",
    " '[마켓인사이트]', '[주목! 딜 종목①]', '[사진]', '[핫이슈]', '[유가증권 기업공시]', '[업종공략]',\n",
    " '[조재길의 경제산책]', '[집중분석 이슈타임]', '[종합]', '[주식 초고수는 지금]', '[영상]', '현대상선','KAI']\n",
    "dataset = pd.read_csv(\"210219_dataset.csv\", encoding=\"euc-kr\")\n",
    "dataset.dropna(inplace = True)\n",
    "companydata = pd.read_csv(\"상장법인목록.csv\",encoding=\"euc-kr\")\n",
    "removeList = companydata['회사명']\n",
    "temp, temp1 = [], \"\"\n",
    "for i in dataset['제목']: \n",
    "    temp1 = i\n",
    "    for j in removeList:\n",
    "        if j in i:\n",
    "            temp1 = i.replace(j, '')\n",
    "            temp1 = temp1.replace(',','')        \n",
    "    temp.append(temp1)\n",
    "dataset['제목'] = temp\n",
    "temp, temp1 = [], \"\"\n",
    "for i in dataset['제목']:   \n",
    "    temp1 = i\n",
    "    for j in removeList2:\n",
    "        if j in i:\n",
    "            temp1 = i.replace(j, '')       \n",
    "    temp.append(temp1)    \n",
    "dataset['제목'] = temp\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('dataset1.csv',encoding=\"\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
